{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahul-jain-7893/PysparkPractice/blob/main/Working_with_RDD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjuAVgrxmIo3"
      },
      "source": [
        "# **Working with RDD (Resilient Distributed Dataset)**\n",
        "\n",
        "**`Udemy Course: Best Hands-on Big Data Practices and Use Cases using PySpark`**\n",
        "\n",
        "**`Author: Amin Karami (PhD, FHEA)`**\n",
        "\n",
        "---\n",
        "\n",
        "**Resilient Distributed Dataset (RDD)**: RDD is the fundamental data structure of Spark. It is fault-tolerant (resilient) and immutable distributed collections of any type of objects.\n",
        "\n",
        "source: https://spark.apache.org/docs/latest/rdd-programming-guide.html\n",
        "\n",
        "source: https://spark.apache.org/docs/latest/api/python/reference/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LWTJaC8mHL5"
      },
      "source": [
        "########## ONLY in Colab ##########\n",
        "!pip3 install pyspark\n",
        "########## ONLY in Colab ##########"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## ONLY in Ubuntu Machine ##########\n",
        "# Load Spark engine\n",
        "!pip3 install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "########## ONLY in Ubuntu Machine ##########"
      ],
      "metadata": {
        "id": "K-riUQ6WTHDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linking with Spark\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "metadata": {
        "id": "e3pTfRiwTMeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing Spark\n",
        "conf = SparkConf().setAppName(\"RDD_practice\").setMaster(\"local[*]\")\n",
        "sc = SparkContext(conf=conf)\n",
        "print(sc)"
      ],
      "metadata": {
        "id": "A_ALGTfeTPN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: Create RDDs and Basic Operations**\n",
        "# **There are two ways to create RDDs:**\n",
        "\n",
        "1.   Parallelizing an existing collection in your driver program\n",
        "2.   Referencing a dataset in an external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat."
      ],
      "metadata": {
        "id": "quQ_GBpgWLRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random data:\n"
      ],
      "metadata": {
        "id": "ILkhrdMMTu9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create RDD:\n"
      ],
      "metadata": {
        "id": "1n39Bv24XHjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data distribution in partitions:\n"
      ],
      "metadata": {
        "id": "b8aOYoMLX7Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print last partition\n"
      ],
      "metadata": {
        "id": "9EffFOyTYC18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count():\n"
      ],
      "metadata": {
        "id": "9TL1kG-Ceo6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first():\n"
      ],
      "metadata": {
        "id": "gZmfAahXeryY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top():\n"
      ],
      "metadata": {
        "id": "OnuGXcKLb8qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distinct():\n"
      ],
      "metadata": {
        "id": "3xOj1w6teN_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map():\n"
      ],
      "metadata": {
        "id": "qE0CJuhlZz1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter():\n"
      ],
      "metadata": {
        "id": "r804677wamjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flatMap():\n"
      ],
      "metadata": {
        "id": "9f--VFpvaqRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive statistics:\n"
      ],
      "metadata": {
        "id": "1LSPGU35gk-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mapPartitions():\n"
      ],
      "metadata": {
        "id": "PEKBDcW1bvZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2: Advanced RDD Transformations and Actions**"
      ],
      "metadata": {
        "id": "EGi2zdncaoHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# union():\n"
      ],
      "metadata": {
        "id": "bIKu4KMrdt1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# intersection():\n"
      ],
      "metadata": {
        "id": "DmQ3bNUkeMVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find empty partitions\n"
      ],
      "metadata": {
        "id": "E2g0ep9M8GX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coalesce(numPartitions):\n"
      ],
      "metadata": {
        "id": "-AopsaZqehmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takeSample(withReplacement, num, [seed])\n"
      ],
      "metadata": {
        "id": "OFjDbelJeuoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takeOrdered(n, [ordering])\n"
      ],
      "metadata": {
        "id": "_K41G_W9ezhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reduce():\n"
      ],
      "metadata": {
        "id": "sgBhaTdAeldY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reduceByKey():\n"
      ],
      "metadata": {
        "id": "aj8-Q40_eXT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sortByKey():\n"
      ],
      "metadata": {
        "id": "Ii8M3qNMeaHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# countByKey()\n"
      ],
      "metadata": {
        "id": "2-WYDKd2e0qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# groupByKey():\n"
      ],
      "metadata": {
        "id": "bihcXC8DeUEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lookup(key):\n"
      ],
      "metadata": {
        "id": "5NzYUXEJhDM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cache:\n",
        "# By default, each transformed RDD may be recomputed each time you run an action on it.\n",
        "# However, you may also persist an RDD in memory using the persist (or cache) method,\n",
        "# in which case Spark will keep the elements around on the cluster for much faster access the next time you query it.\n"
      ],
      "metadata": {
        "id": "g9ThlLGO6z7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persistence (https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence)\n"
      ],
      "metadata": {
        "id": "5zYpm9hpiqPc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}